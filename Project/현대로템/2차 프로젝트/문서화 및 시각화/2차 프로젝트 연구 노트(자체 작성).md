# OMP 충돌 발생 시

정석은 OMP 충돌을 해결하는 것
- 환경 재구축 등

아래의 방법은 OMP 충돌을 무시 + 멀티프로세싱 비활성화 하는 것임

```bash
>>> set KMP_DUPLICATE_LIB_OK=TRUE
>>> set OMP_NUM_THREADS=1
>>> set MKL_NUM_THREADS=1
>>> yolo train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640 batch=16 workers=0
```

# 환경 구축법
마지막 세번째 명령문은 requirments.txt가 있을 때 사용
```bash
>>> conda create -n yolov8_new python=3.9(해당하는 파이썬 버전 입력)
>>> conda activate yolov8_new
>>> pip install -r requirements.txt
```


# 모델 테스트 예시
```bash
yolo predict model=C:/Users/USER/Desktop/yolov8-main/yolov8-main/gkrltlfgdmsrj.v1i.yolov8.copy1/runs/detect/train/weights/best.pt source="C:/Users/USER/Desktop/yolov8-main/yolov8-main/gkrltlfgdmsrj.v1i.yolov8.copy1/test_video_0.mp4" imgsz=640 save=True conf=0.5 show=True
```

## 첫 번째 모델
```bash
(yolov8_env) C:\Users\USER\Desktop\yolov8-main\yolov8-main\gkrltlfgdmsrj.v1i.yolov8.copy

>>> yolo train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640 batch=16 pretrained=True lr0=0.001
```

##  두 번째 모델
```bash
>>> yolo train model=sajeon_haksup.pt data=data.yaml epochs=50 imgsz=640 batch=16 pretrained=True lr0=0.001 freeze=10
```

## 세 번째 파인튜닝
- 소요 시간 : 30m 21s
- 정확도 현저히 떨어짐
- 시도 방안 : 기존 data 와 merge 를 통해 fine tuning
- 학습 결과 : 기존 대비 성능 30% 증가
```bash
(yolov8_env) C:\Users\USER\Desktop\yolov8-main\yolov8-main\gkrltlfgdmsrj.v1i.yolov8.copy1>

>>> yolo train model=sajeon_haksup2.pt data=data.yaml epochs=100 imgsz=640 batch=16 pretrained=True lr0=0.001 freeze=10
```

## 네 번째 하이퍼 파라미터 튜닝
- 소요 시간 : 28m
- 정확도 범위 : 70 ~ 90%
- 정확도 자체의 정밀도는 증가했으나 학교 출석에 사용될 정도로 정밀하지는 않음
- 따라서 하이퍼 파라미터 튜닝 진행 : 
	- lr0=0.001 $\rightarrow$ 0.01 (학습률을 높여 혹시 모를 경사 하강시 발생할 최소 오차 방지)
	- cor_lr=False $\rightarrow$ cor_lr=True (코사인 학습률 스켈쥴러 활성화 통해 학습률을 부드럽게 감소)
- 학습 결과
	- sitae class의 분류 정밀도는 떨어졌지만 나머지 클래스의 분류 정확도가 눈에 띄게 증가됨
```bash
yolo train model=sajeon_haksup2.pt data=data.yaml epochs=100 imgsz=640 batch=16 pretrained=True lr0=0.01 freeze=10 cos_lr=True
```
## 다섯 번쨰 하이퍼 파라미터 튜닝
- 소요 시간 : 
- 기존에는 데이터 증강 기본값을 사용함(mosic=1.0, hsv_h=0.015 emd)
- 데이터 증강 수치 조정
	- close_mosic=5 $\rightarrow$ 모자이크를 마지막 epochs=10 에서 멈추던걸 epochs=5까지 더 오래 유지
	- flipud=0.5 $\rightarrow$ 상하 반적 추가
	- degrees=10.0 회전 증강(10도) 추가
	- translate=0.2, scals=0.9 $\rightarrow$ 이동 및 스케일 증강 강화
- 학습 결과 : 
	- 성능 지표 자체는 좋아졌으나, sitae class의 분류에 난항을 겪고 있음
	- 아마 클래스 자체의 데이터 수의 언벨런스함이 그 이유인 듯 하다
	- 방향은 맞는듯!

```bash
yolo train model=sajeon_haksup2.pt data=data.yaml epochs=100 imgsz=640 batch=16 pretrained=True lr0=0.01 freeze=10 cos_lr=True close_mosaic=5 flipud=0.5 degrees=10.0 translate=0.2 scale=0.9
```

## 여섯 번쨰 하이퍼 파라미터 튜닝
#### 전략적 의도

- **예측 손실 낮추기**: cls 가중치를 3.1로 높이고 box 가중치를 0.15로 낮춘 것은 클래스 분류 손실을 줄이는 데 더 집중하겠다는 전략입니다. 이전 학습 결과에서 val/cls_loss가 3 수준으로 높게 유지된 점을 고려할 때, 클래스 분류 성능을 개선하려는 의도가 명확합니다.
- **일반화 성능 강화**: 데이터 증강(flipud, degrees, translate, scale)과 freeze=10 설정을 통해 모델이 새로운 데이터에 대해 더 잘 일반화되도록 유도했습니다.
- **학습 안정성**: cos_lr=True와 close_mosaic=5를 통해 학습 후반부에 더 세밀한 최적화를 유도하며, 과적합을 방지하려는 의도가 보입니다.

#### 예상 효과

- `cls=3.1`로 인해 클래스 분류 손실(train/cls_loss, val/cls_loss)이 더 빠르게 감소할 가능성이 높습니다.
- `box=0.15`로 인해 바운딩 박스 손실(train/box_loss, val/box_loss)의 감소 속도가 느려질 수 있지만, 이미 낮은 수준이므로 큰 영향을 미치지 않을 가능성이 큽니다.
- Precision과 Recall, mAP 지표에서 클래스 분류 성능 개선으로 인해 전반적인 성능이 향상될 가능성이 있습니다.
```bash
yolo train model=sajeon_haksup2.pt data=data.yaml epochs=100 imgsz=640 batch=16 pretrained=True lr0=0.01 freeze=10 cos_lr=True close_mosaic=5 flipud=0.5 degrees=10.0 translate=0.2 scale=0.9 cls=3.1, box=0.15
```

![[P_curve.png]]

## 일곱 번째 하이퍼 파라미터 튜닝
#### 변경된 파라미터의 의도

- **초기 학습률 감소 (lr0=0.001)**
    - 학습률을 낮추면 모델이 더 천천히 학습하며, 손실 함수의 변화가 더 안정적으로 이루어짐. 이는 여섯 번째 튜닝에서 학습이 다소 급격하게 진행되었거나, 손실이 불안정하게 변동한 경우(예: val/cls_loss의 변동성)를 안정화하려는 의도로 보입니다.
    - 낮은 학습률은 모델이 더 세밀한 최적화 지점으로 수렴하도록 도와주며, 과적합 가능성을 줄이는 데 유용함
- **고정 레이어 감소 (freeze=6)**
    - 고정된 레이어를 10개에서 6개로 줄임으로써 더 많은 레이어가 학습에 참여하게 되었음. 이는 모델이 더 많은 파라미터를 미세 조정(fine-tuning)할 수 있게 하여, 데이터셋에 더 잘 적응하도록 유도함
    - 여섯 번째 튜닝에서 freeze=10으로 설정했을 때 모델이 데이터셋의 특정 패턴을 충분히 학습하지 못했을 가능성을 고려함. 특히, 클래스 분류 성능 개선을 위해 더 많은 레이어가 학습에 참여하도록 한 것임.

#### 전략적 의도

- **학습 안정성 강화**: 낮은 학습률(lr0=0.001)을 통해 손실 함수의 변동성을 줄이고, 더 안정적인 학습을 유도하려는 의도. 이는 특히 val/cls_loss와 같은 손실이 변동이 심하거나 감소가 더딘 경우 유효
- **모델 적응력 강화**: freeze=6으로 고정 레이어를 줄여 모델이 데이터셋에 더 잘 적응하도록 했음. 이는 클래스 분류 성능(cls_loss) 개선과 mAP 지표 향상에 긍정적인 영향을 미칠 가능성 존재.
- **클래스 분류 성능 지속 개선**: cls=3.1과 box=0.15를 유지함으로써 여섯 번째 튜닝의 전략(클래스 분류에 더 집중)을 이어감.

#### 예상 효과

- **손실 안정화**: 낮은 학습률로 인해 train/cls_loss와 val/cls_loss의 감소가 더 안정적으로 이루어질 가능성이 높음. 특히 검증 손실(val/cls_loss)의 변동성이 줄어들 수 있음.
- **성능 향상**: freeze=6으로 더 많은 레이어가 학습에 참여하므로, 모델이 데이터셋의 세부적인 패턴을 더 잘 학습할 가능성이 있음. 이는 mAP@50과 mAP@50:95 지표의 추가적인 향상으로 이어질 수 있음.
- **오버피팅 방지**: 낮은 학습률과 데이터 증강 기법의 조합으로 인해 모델의 일반화 성능이 개선될 가능성이 있음.
```bash
yolo train model=sajeon_haksup2.pt data=data.yaml epochs=100 imgsz=640 batch=16 pretrained=True lr0=0.001 freeze=6 cos_lr=True close_mosaic=5 flipud=0.5 degrees=10.0 translate=0.2 scale=0.9 cls=3.1, box=0.15
```
## 모델 테스트 결과 json 파일로 출력 예시(Grok 도움)

```
```python
from ultralytics import YOLO
import json
import os

model = YOLO("best.pt")

source = "test_video_0.mp4"

results = model.predict(source=source, imgsz=640, conf=0.5, save=True, show=True)

json_data = []
for i, result in enumerate(results):
    frame_data = {
        "frame_id": i,
        "detections": []
    }
    for box in result.boxes:
        detection = {
            "class": result.names[int(box.cls)],
            "confidence": float(box.conf),
            "bbox": [float(coord) for coord in box.xyxy[0]]
        }
        frame_data["detections"].append(detection)
    json_data.append(frame_data)

output_path = "C:/Users/USER/Desktop/detection_results.json"
with open(output_path, "w") as f:
    json.dump(json_data, f, indent=4)

print(f"검출 결과가 {output_path}에 JSON 형식으로 저장되었습니다.")
```