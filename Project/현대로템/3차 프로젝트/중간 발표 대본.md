안녕하세요 저희는 3조, - 이동하고 정지하라. 그리고 적을 탐지하면 사격하라 - 줄여서 이정탐사팀이며, 저는 이정탐사의 이와 정, 그리고 사를 맡고 있는 박현호입니다

(페이지를 넘긴다)

오늘 발표의 목차는 다음과 같습니다.

(페이지를 넘긴다)

저희 팀은 현재 자율 전투 전차의 경로 탐색 및 이동 모듈 개발을 목표로 프로젝트를 진행 중입니다

경로 추종 및 전차 움직임 제어에 초점을 맞췄으며, 규칙 기반 알고리즘을 기반으로 구현을 진행 중에 있습니다

또한 기술을 확장, 강화 학습을 적용해 단계적으로 프로젝트의 완성도를 더욱 높일 예정이며,

코드의 확장성과 유지보수를 고려해 현 절차 지향 프로그래밍 방식에서 객체 지향 프로그래밍 방식으로의 전환을 준비 중입니다.

(페이지를 넘긴다)

저희 팀은 이수호 팀장을 중심으로 구성되었습니다.

이수호 팀장과 김병훈은 강화학습 알고리즘 개발을 담당 중이고,

저, 박현호와 공재국은 경로 계획 및 전차 제어를 위한 고전적인 규칙 기반 알고리즘을 구현 중에 있습니다
(페이지를 넘긴다)

현재 기획, 구현 방안 탐색, 구현 순으로 프로젝트를 진행하였으며 수행 절차 및 방법의 세부 내용은 화면과 같습니다
(페이지를 넘긴다)

경과 보고 드리겠습니다

경로 생성에 대해서는 저희는 가장 보편적인 A* 알고리즘을 채택했습니다

우선 A* 알고리즘에 대해 탐구를 먼저 진행했고, 이를 시뮬레이터 상에 구현했습니다
300×300 크기의 2D 그리드를 구축하고, Y축을 제외한 XZ 좌표를 사용했습니다.

 또한 시뮬레이터 서버의 엔드포인트를 통해 장애물 좌표를 파싱한 뒤, A* 알고리즘을 활용해 목표 지점까지의 최단 경로를 XZ 좌표 리스트로 반환하도록 구현했습니다.
(페이지를 넘긴다)

경로를 정확히 따라가기 위해서는 전차의 움직임을 정밀하게 제어하는 것은 중요합니다. 

이를 위해 시뮬레이션 환경에서 물리량에 대한 데이터를 분석했고, 그 결과를 통해 역치를 추출했습니다.

**회귀분석**을 통해 키보드 입력에 따른 시뮬레이션 kinematic 출력에 대한 물리학적 특성과 탄도학 관련 시스템 함수를 도출했습니다.

또한 **PID 제어**와 게임 AI 기법을 결합해 감속 반경과 정지 반경을 설정했으며, 약간의 조향 오실레이션이 있지만 목표 지점에 도착하는 동작을 구현했습니다.
(페이지를 넘긴다)

위 영상은 앞서 발표했던 A* 알고리즘과 전차 움직임 제어를 결합하여 저희가 정의한 지도에서 최단 경로로 주행하는 것을 구현한 모습입니다

다만, 현재 경로 생성 과정에서 장애물을 따라 이동하는 문제가 발생하고 있습니다. 이를 해결하기 위해 추가적인 최적화 작업을 위해 분전 중입니다.
(페이지를 넘긴다)

저희 프로젝트의 꽃, 강화 학습에 대한 경과 보고 드리겠습니다

강화학습을 본격적으로 구현하기에 앞서, 기초적인 이해를 다지기 위해 **DQN** 알고리즘을 2D 그리드 환경에서 테스트해봤습니다. 

이후, 저희 시뮬레이터 환경에 적합한 알고리즘으로 **PPO**와 **SAC**를 선정했습니다. 

이 두 알고리즘은 저희 시뮬레이션과 같은 연속형 환경에서 강점을 보이기 때문입니다.
(페이지를 넘긴다)

PPO와 SAC 중 PPO부터 먼저 설명 드리겠습니다
Open AI의 **Gym** 패키지를 활용해 시뮬레이션 환경과 PPO를 연동했습니다

하지만 현재 PPO의 학습 성과는 기대에 미치지 못하고 있습니다. 주요 원인은 **낮은 샘플 효율**과 **보상 함수의 민감도**로 분석됩니다.

이를 개선하기 위해 학습 시간을 늘리고, 보상 함수를 더 정교하게 설계할 계획입니다.
(페이지를 넘긴다)

SAC 역시 PPO와 유사하게 시뮬레이션 환경에 연동했지만, 마찬가지로 학습 성과가 기대에 미치지 못하고 있습니다.

 문제점으로는 **낮은 초기 학습률**과 **하이퍼파라미터 민감도**를 꼽을 수 있습니다.

대책으로는 학습 시간을 늘리고, 다양한 하이퍼파라미터 조합을 테스트할 예정입니다.
(페이지를 넘긴다)

오른쪽이 SAC, 왼쪽이 PPO 강화 학습 훈련 중인 모습입니다

아직 최적화가 필요하지만, 꾸준히 개선 중입니다.
(페이지를 넘긴다)

마지막으로, 프로젝트의 평가 및 추후 계획을 말씀드리겠습니다.
 
첫 번째로 알고리즘 기반 탐색/이동 구현은 거의 완료되어, 차후 성능 평가와 최적화에 집중할 예정입니다.

두 번째, 강화 학습 개발 속도에 가속이 필요하며 현재 속도를 높이기 위해 추가적인 리소스 투입과 보상 설계 개선이 필요합니다.

세 번째로는 추가 기능을 구현 예정에 있습니다

추가 기능으로는 사격 통제 및 팀 논의를 통해 발굴된 개선 사항을 구현할 계획입니다.

이상으로 3조 이정탐사팀의 발표를 마치겠습니다. 감사합니다


