---
tags:
  - 딥러닝
  - 케라스
  - 현대로템
---
실행 환경 - google colab

데이터 정보를 selection을 회귀분석을 하거나 앙상블을 활용해, 주요 변량들이 상위에 노출되는 경향이 있기 때문에, 주요 변수들만 뽑아서 모델링을 한면 아쉽운 점은 주요하지 않을 것을 제거할 수는 있지만 영향력이 적더라도 중요한 변량을 포함을 해야 하는 상황도 있다

오버 피팅을하면 차원 저주에 걸릴 수도 있다. 
--> 고유벡터를 추출하는 것도 하나의 방법이다.


- 층이 하나일 떄엔 다중선형회귀분석과 상당히 유사

**Keras 모델을 만드는 방법은 세가지다**
- Sequential 모델 --> 층을 쌓을 수만있음 
- 함수형 API --> 그래프같은 모델 구조
- Model 서브클래싱 --> 밑부터 직접 만들 수 있는 저수준 방법이지만 keras에서는 비추천됨

이중에서 가장 추천되는 것은 Sequential모델, 난이도가 올라가면 함수형 API를 사용.

![[Pasted image 20250224110901.png]]



아래 코드를 돌리면 오류가 뜬다.
model.fit(train_images, train_labels, epochs=3, batch_size=128)
![[Pasted image 20250224122145.png]]

```
Epoch 1/3


---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

[<ipython-input-25-c92435a97b8d>](https://localhost:8080/#) in <cell line: 0>()
      1 #batch_size는 낮추면 낮출 수록 과적합 가능성 높아짐 --> 숫자가 높아지면 일반화가 됨
      2 #epochs 는
----> 3 model.fit(train_images, train_labels, epochs=3, batch_size=128)

---

1 frames

---

[/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py](https://localhost:8080/#) in _adjust_input_rank(self, flat_inputs)
    270                     adjusted.append(ops.expand_dims(x, axis=-1))
    271                     continue
--> 272             raise ValueError(    273                 f"Invalid input shape for input {x}. Expected shape "
    274                 f"{ref_shape}, but input has incompatible shape {x.shape}"

ValueError: Exception encountered when calling Sequential.call().

Invalid input shape for input Tensor("mys_1/Cast:0", shape=(None, 28, 28), dtype=float32). Expected shape (None, 784), but input has incompatible shape (None, 28, 28)

Arguments received by Sequential.call():
  • inputs=tf.Tensor(shape=(None, 28, 28), dtype=uint8)
  • training=True
  • mask=None

```


이것은 데이터 구조가 2차원 데이터를 입력해야하지만 3차원 데이터가 입력되어 오류가 생겼기에 reshape를 사용해서 차원수를 맞춰줘야한다.


## 함수형 API
 - lSequential 모델은 사용하기 쉽지만 적용할 수 있는 곳이 극히 제한적
 - 하나의 입력과 하나의 출력을 가지며 순서대로 층을 쌓은 모델만 표현할 수 있음
 - 실제로 다중 입력(예를 들어 이미지와 이미지의 메타데이터), 다중 출력(예를 들어 데이터에 대해 여러 가지 항목을 예측하는 모델) 또는 비선형적인 구조를 가진 모델을 자주 만날 수 있음

 함수형은 결국 특정 층의 출력을 다른 층의 입력으로 연결해주는 것.


**__call__ 함수**

파이썬 클래스에는 상속이 들어가지만 "__call__" 메소드는 우리가 호출할 수 있는 것이 아닌 시스템에 의해 호출이 **약속** 되어있다.

클래스의 인스턴스를 함수와 동일하게 실행할 수 있게 하여 파이썬의 객체 지향 프로그래밍 패러다임의 다양성을 향상시킨다.


```python
class Test: 
	def __call__(self, x): 
		return x**2 
T = Test() 
print(T(5)) # 출력: 25
```

일반적으로 T(5)를 호출하면 'Test' 객체는 호출 가능한 객체가 아니라는 TypeError가 발생
__call__ 메서드가 정의되어 있어 인자의 제곱을 반환하는 함수와 유사한 결과를 반환

---
---
---
### <b>2025.02.26


## 텍스트 분석
NLP(Natural Language Processing) : 자연어처리
머신러닝이 보편화되면서 NLP와 머신러닝을 구별하는것이 의미가 없어짐 

NLP는 언어를 해석하기 위한 기술, 텍스트 분석은 형태가 텍스트로 이루어진 것을 분석하는 것.

- ___텍스트 분석 > NLP___

자연어 처리란 우리가 사용하는 언어 자체가 가지고 있는 특성을 대화를 하는 것에 초점, 문장, 언어를 생성해 내는 것이다. 텍스트 자체를 분석하는 것이 텍스트 분석


___텍스트(Text)___
  - 표준화  == 어근화(steming)
  - 구두문자

 표준화 관련해서는 너무나도 많은(수학, 문법 요소) 등이 작용한다.
 
 머신러닝은 단어와 단어 사이의 연관 관계는 알 수 있지만 순서관계는 알 수가 없음
 -> 확률값으로 등장횟수(frequency)만을 계산하기 때문
 
  위 문제들을 해결한 것이 딥러닝

## 불용어 (스톱 워드) 제거

- 스톱 워드 : 분석에 큰 의미가 없는 단어 지칭. 필수 문법 요소이지만 문맥적으로 큰 의미가 없는 단어가 이에 해당.
- 불용어를 사전에 제거하지 않으면 그 빈번함으로 인해 오히려 중요한 단어로 인지될 수 있음. 그러므로 사전에 제거해주는 과정 수행해야 함.

word = re.sub(r"[^\w\s]","",word) --> ^은 뒤에 들어오는 것 제외 모두 삭제하라는 뜻이고 ^이 없으면 저기 있는 거만 삭제가 됨

# Bag of Words – BOW

## 사이킷런의 Count 및 TF-IDF 벡터화 구현 : CountVectorizer, TfidfVectorizer

- 단어 피처에 값을 부여할 때 각 문서에서해당 단어가 나타나는 횟수(Count)를 부여하는 것을 카운트 벡터화라고 함  
- CountVectorizer : 카운트 기반의 벡터화를 구현한 클래스, 단순 피처 벡터화만 아닌 소문자 일괄 변환, 토큰화 등 텍스트 전처리도 함께 수행.
- 카운트만 부여할 경우 그 문서의 특징을 나타내기보다는 언어의 특성상 문장에서 자주 사용될 수 밖에 없는 단어까지 높은 값을 부여 

## BOW 벡터화를 위한 희소 행렬

- 사이킷 런에서 CountVectorizer, TfidfVectorizer을 이용해 텍스트를 피처 단위로 벡터화해 변환하고 CSR 형태의 희소 행렬을 반환하지만, 좀 더 난이도가 있는 ML 모델을 수립하기 위해서는 이러한 희소 행렬이 어떤 형태로 돼있는지 알아야 함.
- n-gram을 사용하면 칼럼 수는 더 증가할 수 밖에 없지만, 대규모 행렬이 생성되더라도 레코드의 각 문서가 가지는 단어의 수는 제한적이기에 이 행렬의 값은 대부분 0이 차지함.

![[Pasted image 20250226130531.png]]

이러한 희소 행렬은 물리적으로 적은 메모리 공간을 사용할 수 있게 변경해줘야 함. → COO, CSR 이 있는데, 일반적으로 CSR을 많이 사용

- COO 형식 : 0이 아닌 데이터만 별도의 데이터 배열에 저장하고 그 데이터가 가리키는 행과 열의 위치를 별도의 배열로 저장하는 방식 [[3,0,1], [0,2,0]]일 때, 0이 아닌 데이터는 [3,1,2]이고, (row, col)로 나타내면 (0,0), (0,2), (1,1)이 됨. 로우, 칼럼을 별도로 저장하면 로우는 [0,0,1], 칼럼은 [0,2,1]
- CSR 형식 : COO 형식이 행과 열의 위치를 나타내기 위해서 반복적인 위치 데이터를 사용해야 하는 문제점을 해결하는 방식

![[Pasted image 20250226130835.png]]

순차적으로 같은 값이 반복적으로 나오는 것을 확인할 수 있는데, 행 위치 배열의 고유한 값의 시작 위치만 표기하는 방법으로 이러한 반복 제거 가능

![[Pasted image 20250226130856.png]]

---
### <b>2025.02.27

IMBD 실습(영화리뷰 분석) --> 이진 분류 문제(텍스트분석)

![[Pasted image 20250227100219.png]]

위와 같이 데이터 길이가 들쑥 날쑥하기에 비정형으로 분류한다.

등장한 단어들의 빈도수 활용해 긍정, 부정을 판별하는 것

인공신경망은 일반적으로 머신러닝(지도학습)이지만
층이 깊어지면 딥러닝(비지도학습)으로 넘어갈 수도 있음.

계속 학습을 하다 보면 과대적합이 되기 때문에, 학습데이터를 밸리데이션(유효검사)를 해서 중간에 학습 정확도를 판단한다. 
 _epoch가 늘어나면 늘어날 수록 정확도는 늘어나지만...과대적합 가능

파이토치나 파이참 등 엔진을 사용하는 이유는 계산 중간에 터져도 가장 좋았던 모델을 저장하기에 사용한다.

텐서플로우를 배운 사람 입장에서 사이킷런은 너무 가볍다.

<b> 텐서플로우는 단순한 라이브러리가 아닌 AI프레임워크라고 말해야한다.

```python
word_index = imdb.get_word_index()
reverse_word_index = dict(
    [(value, key) for (key, value) in word_index.items()])
```


위 코드에서 튜플을 리스트로 만들고 key와 value의 순서를 바꿔서 리턴 후 딕셔너리 구조로 편성함 

```python
decoded_review = " ".join(
    [reverse_word_index.get(i - 3, "?") for i in train_data[0]])
```

## 실무에서 딥러닝 사용시 알고리즘은 거의 수정하지 않는다
- 자료구조를 내 데이터와 맞춰주는 것
- 맞춘 데이터를 적용 시키고 돌린 후 정확도를 올리기 위한 하이퍼파라미터 튜닝
- 출력제어가 불안정 시 다른 모델 사용

---
### <b> 2025.02.28

## 임베딩(Embedding)

텍스트 처리 과정
- 비정형 --> 정형화된 구조화 --> 학습모델생성

단어간의 순차적 등장 == 유사성

1) BOW - document-term 행렬
2) **임베딩(Embedding)**

참고 자료:
[09-03 영어/한국어 Word2Vec 실습 - 딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/50739)

임베딩(인코딩) - 단어(문장)을 수치화
1. 원-핫 인코딩
	- 단점: 차원저주, 의미적 관계 없음 
![[Pasted image 20250228095259.png]]
<br>
2. 임베딩 기술
	- 벡터간의 상관관계 파악 가능, 의미적 관계 있음
![[Pasted image 20250228095953.png]]


책 추천: 수학자가 들려주는 수학 이야기
~~도서관 가서 읽어보는 걸로 하자~~

윈도우 사이즈가 나를 제외한 앞뒤 문자들의 개수를 말하는 것이며, 이를 통해 문맥을 학습시킨다.

![[Pasted image 20250228101514.png]]

최종 임베딩 정보는 h이며, 이러한 값들이 나올 수 있게 하는 것이 **word2vec**이다.

시각적으로 사용할 때 html 사용

html은 마크업 언어로 계층구조(요소, 주성분)를 가짐
모델링 정보를 확장자를 정한 후 임포트 후에 form을 통한 GUI기반 인공지능 서비스를 구현할 수 있음

```html
<!DOCTYPE html>

<html lang="en"><!--element/attribute-->

    <head>

        <style type="text/css">

            h1 {

                background-color: red;

                color: white;

            }

            </style>

    </head>

    <body>

        <h1>입력정보</h1><!--헤드라인-->

        <form action="check.py" method="POST">

            <label for="nid">아이디:</label>

            <input id="nid" type="text" name="">

            <input type="date" name="date">

            <input type="color" name="color">

            <button>전송</button>

        </form>

    </body>

</html>
```
**실행화면**
![[Pasted image 20250228113842.png]]

예전에는 하나의 페이지를 수정하려면 모든 것을 다 바꿔야했지만,
최근에는 한줄 한줄이 자원이며, 하나만 탐색 후 수정함.

HTML의 스타일이 개인화 되기 위해 css 등장
계층구조이기에 부모의 요소(html)를 받아 사용(css)

html = 구조 + data + 스타일
여기서 data는 XML로 사용하며 데이터 전송규약이다.

```xml
<?xml version="1.0" encoding="UTF-8"?>

<students>

    <student sid ="1">

        <sname>홍길동</sname>

        <dept>컴퓨터</dept>

    </student>

    <student sid ="2">

        <sname>김길동</sname>

        <dept>경영학</dept>

    </student>

</students>
```

**실행화면**
![[Pasted image 20250228113913.png]]

- 여기서 첫번째 줄은 선언문
- sname, dept 사이에 있는게 실데이터, 
- sname, dept는 실데이터를 설명하는 메타데이터이다.

model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)

여기서 vector_size와 window의 값을 어떻게 정하는지를 알아야한다.

- min_count는 출현빈도가 최소 5인 단어만 학습에 사용한다는 의미
- windows=5는 중심단어의 앞과 뒤로 5번째 단어까지 학습용 데이터로 사용 
- 벡터의 크기는 100입니다. count 단어들 중 빈도가 5이상인 단어들은 100개의 숫자로 구성된 벡터로 변환

단어 벡터를 word2vec로 만들지 않고 케라스 클라스인 Embedding을 사용하면
단어를 vectorizing 했을 때 word2vec처럼 vectorizing 해서 제공을 해준다.

고로 굳이 word2vec를 사용할 필요는 없다.

---

## 컴퓨터비전을 위한 딥러닝

	딥러닝 - 컨볼루셔널 네트워크를 이용한 이미지 인식의 개념
	
Convolutional neural network(CNN)은 **합성곱 신경망** 을 의미한다

![[Pasted image 20250228145454.png]]


### **CNN 원리**
1. 컨볼루셔널 계층을 통해서 입력 받은 이미지에 대한 특징(Feature)를 추출

2. 추출된 특징을 기반으로 기존의 뉴럴 네트워크를 이용하여 분류

각 dense 마다 필터가 되어 그 정보가 y(분류값)에 가까이 가게 되는 것이 CNN이다.

합성곱은 2차원 행렬로 계산하며 이 때 2차원 피쳐맵이 생성된다. --> 정확도 상승 요인

![[Pasted image 20250228145915.png]]![[Pasted image 20250228145925.png]]

이렇게 만들어진 합성곱연산은 2차원으로 슬라이싱하한다. 

앞서봤던 머신러닝은 1차원이었기에 특정위치에 특성을 찾는 것이었다.

하지만 합성곱연산은 슬라이싱 특성 정보를 가지고 연산을 하기에 층의 깊이가 깊어지고,
따라서 정확도가 높아진다.

## Max pooling (맥스 풀링) 

맥스 풀링은 Activation map을 MxN의 크기로 잘라낸 후, 그 안에서 가장 큰 값을 뽑아내는 방법이다.

아래 그림을 보면 4x4 Activation map에서 2x2 맥스 풀링 필터를 stride를 2로 하여 2칸씩 이동하면서 맥스 풀링을 한 예인데, 좌측 상단에서는 6이 가장 큰 값이기 때문에 6을 뽑아내고, 우측 상단에는 2,4,7,8 중 8 이 가장 크기 때문에 8을 뽑아 내었다. 

![[Pasted image 20250228150427.png]]

맥스풀링을 넣는 이유
 1. 전체 데이터 사이즈가 줄어들어 연산 컴퓨팅 리소스가 적어짐
 2. 데이터 크기를 줄이면서 소실이 발생하기에 과적합(overfitting)을 방지

- Conv2D에서 filter가 가중치 w이다

---
---
---
### <b>2025.03.04

```python
callbacks = [

    keras.callbacks.ModelCheckpoint(

        filepath="convnet_from_scratch.keras",

        save_best_only=True,

        monitor="val_loss")

]

history = model.fit(

    train_dataset,

    epochs=30,

    validation_data=validation_dataset,

    callbacks=callbacks)
```

콜백을 통해 반드시 딥러닝 학습 중간중간에 저장, 인섹시켜야한다.

- 특성추출
- 미세조정

---
---
---
## 2025.03.05

### 사전 훈련된 모델 활용하기

사람은 어떠한 필터를 가지고 합성곱을 했길래(어떤 feature을 가지고 있길래) 를 궁금해한다. 

$\rightarrow$ 하위층에서는 일반적 특성 학습, 
$\rightarrow$ 상위층으로 갈 수록 디테일한 특성 학습이 이뤄진다.

- 합성곱 층에 의해 학습된 표현은 일반적이어서 재사용이 가능함

- 컨브넷의 특성 맵은 이미지에 대한 일반적인 콘셉트의 존재 여부를 기록한 맵

- 주어진 컴퓨터 비전 문제에 상관없이 유용하게 사용할 수 있음

- 분류기에서 학습한 표현은 모델이 훈련된 클래스 집합에 특화되어 있음

- 분류기는 전체 사진에 어떤 클래스가 존재할 확률에 관한 정보만 담고 있음

- 더군다나 밀집 연결 층에서 찾은 표현은 더 이상 입력 이미지에 있는 객체의 위치 정보를 가지고 있지 않음

- 밀집 연결 층들은 공간 개념을 제거하지만 합성곱의 특성 맵은 객체 위치를 고려

- 객체 위치가 중요한 문제라면 밀집 연결 층에서 만든 특성은 크게 쓸모없음

ImageNet 모델 굉장히 유명한~~
이미지 셋을 가지고 있고 이를 활용해 대회를 개최 좋은 성적을 내는 알고리즘들이 있기에 검증된 데이터 셋이라고 볼 수 있음.

이 ImageNet 모델에는 강아지와 고양이도 포함됨.
이미지 학습된 모델을 케라스에서 지원을 하며, 이를 재활용해 특성 추출(feature)을 실행

케라스의 ImageNet 알고리즘 $\rightarrow$ VGG16

이것을 가지고 사전 훈련 모델 사용법을 실습할 것임.

그대로 활용하기 VS 튜닝하기

CNN은 필터(layer)를 찾는 과정을 학습한다.

학습된 모델에는 이미 필터(가중치, 편향 등)가 정의 되어 있다.

전체를 그대로 쓰자 $\rightarrow$ 특성 추출
전체에서 일부만 쓰자 $\rightarrow$ 파인 튜닝

VGG 알고리즘에서 계산은 3*3이 가장 빠르더라

**파인튜닝**

내가 준비한 데이터를 뉴럴 네트워크에 넣고 분류하는 것
conv vgg맵을 만들어 피쳐맵을 만들고, my_data가 모델을 통과 시켜서 피쳐맵을 만들어야 나만의 뉴럴네트워크를 학습할 수 있는 것임


---
---
---
## 2025.03.06


**OCR**

OCR(Optical Character Recognition, 광학 문자 인식)은 문서를 디지털화하는 가장 기본적인 기술

스캔된 종이 문서, PDF 파일, 사진 등 다양한 소스에서 텍스트를 추출하여 검색 가능한 디지털 문서로 변환하거나 데이터베이스화할 수 있음

**동작 원리**

**1. 이미지 전처리**:

- 텍스트와 배경을 구분하고 왜곡된 이미지를 보정

- 노이즈 제거와 이진화 처리로 텍스트를 명확히 분리

**2. 문자 세분화**:

- 텍스트를 개별 문자, 단어, 줄 단위로 나눔

**3. 문자 인식**:

**- 패턴 매칭**: 기존 데이터베이스와 비교하여 문자를 식별

**- 딥러닝 기반 AI 모델**: 문맥을 분석해 복잡한 언어와 문서를 처리

**4. 결과 출력**:

디지털 텍스트로 변환 후 저장하거나 활용 가능한 형태로 가공

![[Pasted image 20250306102644.png]]


**주요 OCR 오픈소스 도구**

Tesseract OCR: 구글 지원 오픈소스로 다국어 지원 및 커스터마이징 가능

EasyOCR: 딥러닝 기반으로 설치가 간편하고 높은 성능 제공

Google Cloud Vision: 다국어 지원, 클라우드 기반 확장성 및 이미지 분석 기능 포함

네이버 Clova OCR: 표, 차트 등 다양한 문서 형태를 처리하는 한국어 중심 솔루션



사실 OpenCV에도 OCR이 적용되어 있긴 하다

기존 OCR은 규칙 기반으로 동작함 $\rightarrow$ 정형화된 문서에 적합
$but$ 비정형 데이터와 다국어 처리에는 한계 존재


AI OCR은 딥러닝 기술을 활용하여 문맥 이해와 자연어 처리 능력을 갖춤 
$\rightarrow$ 왜곡된 이미지, 복잡한 문서, 다국어 텍스트에서도 뛰어난 성능을 보임

문자 인식 이후에는 패턴 찾기까지 유기적으로 연결


**opencv**

- 그래픽 기반 프로그램들은 모듈화를 해야함
- 어떤 요청이 들어오냐에 따라 실행 순서가 정해짐
- 각각의 기능들이 완벽하게 독립적이어야함 $\rightarrow$ gui설계가 어려운 이유

독립적으로 실행되어야하는 GUI 화면을 종료하는 것 $\rightarrow$ **callback**으로 선언해야 함



