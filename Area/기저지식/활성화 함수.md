- 분류 모형(문제)일 때 활성화 함수 사용 O
- 회귀 모형(문제)일 때 활성화 함수 사용 O

# 활성화 함수란? 

- 딥러닝 네트워크(인공 신경망)에서 노드에 입력된 신호의 총합을 출력 신호로 변환하는 함수를 뜻하며 뉴런의 출력을 다음 레이어에 입력하는 값을 정하는 비선형 변환 함수임.


활성화 함수로 선형 함수를 사용할 수 있지만 일반적으로 비선형 함수가 지향됨

선형 함수의 한계로 인해 딥러닝 모델의 레이어 층을 깊게 가져가지 못하기 때문임

# 활성화 함수의 역할

선형 함수 $h(x) = cx$를 사용한 3층 네트워크는 다음과 같이 표현이 가능함

$y(x) = y(y(y(x)))$

하지만 h(x)가 선형적이기에 위 식은 다음과 같이 간단히 표현이 가능함

$a = c3$
$y(x) = ax$

일차식의 한계로 인해 여러 층으로 구성하는 이점을 살릴 수 없는 단순한 선형 모델로 동작하여 은닉층이 없는 네트워크로 표현이 가능하며 이는 복잡한 문제에는 사용이 불가함을 시사함

비선형 활성화 함수는 다음과 같은 역할을 수행함
### 비선형 활성화 함수의 역할
- 비선형성 도입
	- 신경망이 복잡한 패턴을 학습하고 비선형적인 관계를 모델링
- 출력값 제한함
	- 활성화 함수는 뉴런의 출력을 특정 범위로 제한하기에 출력 값의 이상치를 방지함
- 학습 가능성 보장
	- 경사 하강법과 같은 최적화 알고리즘에서 미분을 통해 손실을 줄여나가는 과정에서 미분 가능성을 보장함

선형 함수를 활성화 함수로 사용하는 경우는 다음과 같다
### 선형 활성화 함수의 역할
- 출력층에서 연속적인 값들을 사용한 회귀 문제를 해결할 때 사용됨
- 은닉층에서는 제한되며 출력층에 국한돼서 사용

# 활성화 함수의 종류

## 시그모이드(sigmoid) 함수

- 시그모이드(sigmoid)란 'S자 모양'이란 뜻이며 실수 x의 값에 따라 0~1의 압축값을 출력을 가짐
- 로지스틱(Logistic) 함수라고도 불림
- 주로 이진 분류 문제에서 사용되며 미분이 가능함
![[활성화 함수-20250328.png|500]]

### 시그모이드(sigmoid) 함수의 단점
- 시그모이드 함수의 기울기는 입력이 0일 때 가장 크고, |x| 가 클수록 기울기는 0에 수렴함
- 음수 값을 0에 가깝게 표현하기 때문에 입력 값이 최종 레이어에서 미치는 영향이 적어지는 Vanishing Gradient Problem이 발생함
- 딥러닝 학습 과정 중 Back - propagation을 계산 시 시그모이드 함수를 활용한 은닉층의 깊이가 깊으면 기울기가 소실되는 문제가 발생해 오차율을 계산하기가 어려움

	- [ ] Back - propagation : 활성화 함수의 미분을 값을 곱한 값
	- [ ] 아래의 그림에서 보이듯 시그모이드 함수의 미분 계수는 0.25임

![[활성화 함수-20250328-2.png|500]]

### 시그모이드(sigmoid) 함수 미분 과정

$\begin{aligned} \frac{d}{dx} \text{sigmoid}(x) &= \frac{d}{dx} \left( 1 + e^{-x} \right)^{-1} \\ &= (-1) \left( 1 + e^{-x} \right)^{-2} \frac{d}{dx} \left( 1 + e^{-x} \right) \\ &= (-1) \left( 1 + e^{-x} \right)^{-2} \left( 0 + e^{-x} \frac{d}{dx} (-x) \right) \\ &= (-1) \left( 1 + e^{-x} \right)^{-2} e^{-x} (-1) \\ &= \frac{e^{-x}}{\left( 1 + e^{-x} \right)^2} \\ &= \frac{1 + e^{-x} - 1}{\left( 1 + e^{-x} \right)^2} \\ &= \frac{1 + e^{-x}}{\left( 1 + e^{-x} \right)^2} - \frac{1}{\left( 1 + e^{-x} \right)^2} \\ &= \frac{1}{1 + e^{-x}} - \frac{1}{\left( 1 + e^{-x} \right)^2} \\ &= \frac{1}{1 + e^{-x}} \left( 1 - \frac{1}{1 + e^{-x}} \right) \\ &= \text{sigmoid}(x) \left( 1 - \text{sigmoid}(x) \right) \end{aligned}$



