- **정의**: 텍스트 마이닝 전에 원시 데이터를 모델이 이해할 수 있게 다듬는 과정.
- **주요 단계**:
    1. **토큰화(Tokenization)**: "I like cats" → ["I", "like", "cats"].
    2. **정규화(Normalization)**: "Cats"와 "cats" 통일, 오타 수정.
    3. **불용어 제거(Stopword Removal)**: "the", "is" 같은 단어 삭제.
    4. **어간 추출(Stemming)**: "running" → "run".
    5. **표제어 추출(Lemmatization)**: "better" → "good" (문맥 고려).

[[기획 및 데이터 전처리]]와도 일맥상통하는 부분이 있음