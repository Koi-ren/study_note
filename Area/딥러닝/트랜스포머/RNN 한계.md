- **RNN 기본**: 시퀀스 데이터를 순차적으로 처리, 과거 정보 기억.
- **문제점**:
    1. **기울기 소실(Vanishing Gradient)**: 긴 문장에서 앞부분 잊어버림.
        - 예: "I went to school and..." 뒤로 갈수록 "school" 영향 약해짐.
    2. **병렬 처리 불가**: 한 번에 하나씩 계산 → 느림.
- **해결 시도**: LSTM, GRU로 보완했지만 완벽하진 않았음.
- → [[트랜스포머]]가 이 한계를 깨부숨.