# 1. 개요
전차 시뮬레이터의 자동 조준을 구현하려고 한다.
자동 조준에 대해 이야기하기 이전 단어의 정의에 대해서 먼저 정의를 할 것이며, 자동 사격통제에 대한 나의 정의는 다음과 같다

*적을, 또는 적의 이동 방향을 자동으로 조준하여 타격하는 것* 

따라서 적을 향하는 방법과 적의 이동 방향을 예측하는 것이 중간 목표이다

# 2. 적을 향해 조준하는 법
적을 조준하는 법은 세 가지로 사료된다
1. 이미지에서 검출된 적의 위치를 이용하는 것
2. 시뮬레이션 정보에 대한 적의 위치를 참조하여 조준하는 것
3. 위 두 개를 합친 것
`참고로 적을 조준하는 각 방법은 모두 문제가 있다.`
후술에서는 위 세 방법에 대해서 기술할 것이며, 각 요소들에 대한 의사 코드를 작성할 것이다
또한 여기서는 카메라로는 조준 목표에 대한 distance 요소를 검출할 수 없다는 가정 하에 작성한다
## 2.1. 이미지에서 검출된 적의 위치에 대한 것

![[자동 조준 메커니즘에 대한 고찰-20250430-1.png|500]]

우선 완벽한 평면 상에 관찰자와 조준 목표가 있다고 가정한다 
관찰자의 시야에서 적의 위치 움직임은 한 축(이하 고정 이동축)에서만 동작한다
왜냐하면 평면 상에서의 움직임은 같은 평면의 존재에게는 점이 좌우로 움직이는 것과 마찬가지 이기 때문이다 
- FPS 게임 CS:GO에서의 예시를 들자면 헤드라인을 잡는 것과 똑같다.
- 유효 사거리 내에서 적의 헤드라인은 거의 일정한 높이를 지니고 있다

![[자동 조준 메커니즘에 대한 고찰-20250430.png|500]]
물론 이것은 발사 시 직선 방향으로 즉시 타격하는 히트스캔 방식에서는 통용되는 방식이지만 문제는 우리 시뮬레이터의 화기는 곡사의 형태를 띄는 투사체 방식이기에 거리 값과 탄속에 따른 투발 시간 대비 피격 시간인 $\theta \text{t}$를 고려해야 한다

따라서 우리는 카메라를 통해 받아온 이미지 데이터만으로 적을 조준한다면, 이는 적에 대한 관찰 이동 축으로 적에 대한 조준하는 용도와 조정에 대한 값을 보정하는 용도로 사용하는 것이 좋은 방법이라고 판단된다.
## 2.2. 시뮬레이션 정보에 대한 적의 위치를 참조하는 것
시뮬레이션의 엔드포인트 `/info`에서 파싱되는 정보는 다음과 같은 형식이다

```json
{
   "time":3.9867117404937744,
   "distance":252.40330505371094,
   "playerPos":{
      "x":60.0,
      "y":8.002116203308105,
      "z":27.229999542236328
   },
   "playerSpeed":0.2987206280231476,
   "playerHealth":100.0,
   "playerTurretX":2.9181717042803257e-09,
   "playerTurretY":0.0,
   "playerBodyX":2.9181717042803257e-09,
   "playerBodyY":-3.256887814995224e-11,
   "playerBodyZ":-9.338149453697042e-08,
   "enemyPos":{
      "x":59.22119903564453,
      "y":8.869277954101562,
      "z":279.630615234375
   },
   "enemySpeed":19.135791778564453,
   "enemyHealth":100.0,
   "enemyTurretX":179.5301055908203,
   "enemyTurretY":-2.180685520172119,
   "enemyBodyX":179.5301055908203,
   "enemyBodyY":2.180685520172119,
   "enemyBodyZ":2.2678720951080322,
   .
   .
   .
   .
   ]
}
```

우리는 위 json 형식의 데이터에서 적에 대한 여러가지 정보를 얻을 수 있다

**정보 리스트**:
1. distance(적과 나의 거리)
2. playerPos
3. playerSpeed
4. playerBodyX
5. playerTurretX
6. enemyPos
7. enemySpeed
8. enemyBodyX

위 여덟 가지 데이터를 통해 우리는 적의 위치를 특정 및 사거리 계산 등 여러가지 작업을 할 수 있으며 이에 대한 작업은 후술한다

1. distance:
	1. 포신의 신뢰 사거리에 따른 오차범위 선정
	2. 포신 각도 선정
2. playerBodyX, enemyBodyX, playerSpeed, enemySpeed, playerPos, enemyPos
	1. player의 로컬 좌표계(고정 이동축) 내에서의 enemy에 대한 상대 속도를 지정
		1. 고정 이동축에서의 단위 벡터, 속력을 통해 적의 이동 방향을 예측(2차원 데이터를 1차원으로 압축하는 개념)
3. playerTurretX, playerPos, enemyPos
	1. 적의 좌표와 player의 좌표를 통해 타겟 조준 헤딩 값 선정

고로 `/info`에서 제공되는 데이터 만으로도 조준 및 사격이 가능하다
## 2.3. 이미지 데이터의 검출 값과 시뮬레이션 정보를 퓨전하는 것

2.2 에서 이미 우리는 완벽한 조준 사격이 가능하다는 것을 이론적으로 알고 있다
그렇다면 왜 우리는 2.1과 2.2를 fusion 해야 하는 것일까?

이에 대한 나의 대답은 아래와 같다

*`/info` 엔드 포인트의 데이터는 지형지물에 대한 정보가 미포함되어있다*

따라서 우리는 카메라를 통해 지형과 전차 앞의 장애물에 대한 정보를 확인 해야 한다

심 봉사가 대략적인 위치만 듣고 수류탄을 던질 수는 없는 노릇이다
반드시 거기에 피해를 볼 수 있는 다른 무언가가 있는지, 수류탄의 궤도에 장애물은 없는 지를 확인해야만 안전하게 적을 사살할 수 있을 것이기 때문이다

따라서 카메라를 통해 타겟이 포착이 되면 위의 메커니즘이 실행되도록 해야한다

이를 블록선도로 표현하면 다음과 같다